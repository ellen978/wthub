{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/jingyan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re   \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import collections\n",
    "import nltk  \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import PorterStemmer, WordNetLemmatizer  \n",
    "import string\n",
    "from decimal import *\n",
    "import sys\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and read-in  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question_type</th>\n",
       "      <th>survey_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In this survey, you will be presented with two versions of \"Getting Started\" options within a mortgage section of a bank's website. ​​​​​​​Please take a few minutes to answer the following questions. Remember to keep the link to the first design version open in a separate window so you can later compare it with the second design version that will be presented to you later on. Thank you in advance for your participation.</td>\n",
       "      <td>0</td>\n",
       "      <td>description</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Which of the below best describes your current status?</td>\n",
       "      <td>2</td>\n",
       "      <td>single-select</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Referring to the image you have open... ​​​​​​​ If you are purchasing your first home and are interested in using a bank to get a mortgage, which option (if any) would you choose ?</td>\n",
       "      <td>3</td>\n",
       "      <td>single-select</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What are your impressions of the options you were provided with?</td>\n",
       "      <td>4</td>\n",
       "      <td>rate</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How clear or unclear are the options you were provided with?</td>\n",
       "      <td>5</td>\n",
       "      <td>single-select</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0  0            \n",
       "1  1            \n",
       "2  2            \n",
       "3  3            \n",
       "4  4            \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                  question  \\\n",
       "0  In this survey, you will be presented with two versions of \"Getting Started\" options within a mortgage section of a bank's website. ​​​​​​​Please take a few minutes to answer the following questions. Remember to keep the link to the first design version open in a separate window so you can later compare it with the second design version that will be presented to you later on. Thank you in advance for your participation.   \n",
       "1  Which of the below best describes your current status?                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "2  Referring to the image you have open... ​​​​​​​ If you are purchasing your first home and are interested in using a bank to get a mortgage, which option (if any) would you choose ?                                                                                                                                                                                                                                                      \n",
       "3  What are your impressions of the options you were provided with?                                                                                                                                                                                                                                                                                                                                                                          \n",
       "4  How clear or unclear are the options you were provided with?                                                                                                                                                                                                                                                                                                                                                                              \n",
       "\n",
       "   question_id  question_type survey_id  \n",
       "0  0            description    216       \n",
       "1  2            single-select  216       \n",
       "2  3            single-select  216       \n",
       "3  4            rate           216       \n",
       "4  5            single-select  216       "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('takehome_ml_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single-select    607\n",
       "textarea         541\n",
       "rate             285\n",
       "description      271\n",
       "multi-select     126\n",
       "matrix-likert    106\n",
       "number           10 \n",
       "rank             6  \n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question_type'].value_counts() #8 question types; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning question texts   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['question_c'] = data['question'].fillna('')\n",
    "data['question_c']=data['question_c'].str.lower()\n",
    "data['question_c']=data['question_c'].str.split()\n",
    "data['question_c']=data['question_c'].apply(lambda x: [re.sub('[^a-zA-Z]*', '', i) for i in x])\n",
    "data['question_c']=data['question_c'].apply(lambda x: [c for c in x if not c.isdigit()])\n",
    "\n",
    "'''\n",
    "def get_wordnet_pos(tag):  \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN \n",
    "    elif tag.startswith('R'):  \n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def normalize(text):\n",
    "    word_pos = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    lemm_words = [nltk.WordNetLemmatizer().lemmatize(w[0], get_wordnet_pos(w[1])) for w in word_pos]  \n",
    "    return [x.lower() for x in lemm_words]\n",
    "data['question_c']=data['question_c'].apply(lambda x: ' '.join(x))\n",
    "data['question_c']=data['question_c'].apply(normalize)\n",
    "'''\n",
    "\n",
    "a={'what', 'which', 'who', 'whom', 'or', 'above', 'below', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "'both', 'each', 'more', 'most', 'no', 'nor', 'not', 'only', 'than', 'very'} \n",
    "b={'would'}         \n",
    "c=set(stopwords.words('english'))\n",
    "sw=c|b \n",
    "sw=sw-a\n",
    "data['question_c']=data['question_c'].apply(lambda x: ' '.join([c for c in x if c not in sw]))\n",
    "\n",
    "def dfdic(text):    \n",
    "    dic={}  \n",
    "    for i in text: \n",
    "        for j in set(i.split()):\n",
    "            if j in dic:\n",
    "                dic[j]+=1\n",
    "            else:    \n",
    "                dic[j]=1  \n",
    "    return dic  \n",
    "dic=dfdic(data['question_c'])  \n",
    "sw2={k for k, v in dic.items() if len(k)==1 or v==1}  \n",
    "data['question_c']=data['question_c'].apply(lambda x: ' '.join([c for c in x.split() if c not in sw2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization/stemming is opted out above since plural format of words (esp. nouns) helps to differentiate some question types (e.g. single-select v.s. multi-select). Omitting it turned out better predicition performance.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Top 10 most frequently appeared words under each questioin type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': ['link',\n",
       "  'survey',\n",
       "  'please',\n",
       "  'take',\n",
       "  'click',\n",
       "  'below',\n",
       "  'next',\n",
       "  'page',\n",
       "  'feedback',\n",
       "  'like'],\n",
       " 'single-select': ['which',\n",
       "  'best',\n",
       "  'how',\n",
       "  'or',\n",
       "  'following',\n",
       "  'what',\n",
       "  'use',\n",
       "  'product',\n",
       "  'find'],\n",
       " 'rate': ['what',\n",
       "  'how',\n",
       "  'likely',\n",
       "  'rate',\n",
       "  'reaction',\n",
       "  'or',\n",
       "  'product',\n",
       "  'find',\n",
       "  'easy',\n",
       "  'page'],\n",
       " 'multi-select': ['which',\n",
       "  'please',\n",
       "  'select',\n",
       "  'following',\n",
       "  'or',\n",
       "  'what',\n",
       "  'how',\n",
       "  'use',\n",
       "  'any'],\n",
       " 'textarea': ['why',\n",
       "  'please',\n",
       "  'what',\n",
       "  'how',\n",
       "  'like',\n",
       "  'most',\n",
       "  'make',\n",
       "  'describe',\n",
       "  'or',\n",
       "  'product'],\n",
       " 'matrix-likert': ['terms',\n",
       "  'how',\n",
       "  'following',\n",
       "  'rate',\n",
       "  'not',\n",
       "  'or',\n",
       "  'important',\n",
       "  'satisfied',\n",
       "  'current',\n",
       "  'na'],\n",
       " 'number': ['product',\n",
       "  'price',\n",
       "  'what',\n",
       "  'think',\n",
       "  'begin',\n",
       "  'expensive',\n",
       "  'consider'],\n",
       " 'rank': ['order',\n",
       "  'least',\n",
       "  'first',\n",
       "  'please',\n",
       "  'following',\n",
       "  'where',\n",
       "  'most',\n",
       "  'last',\n",
       "  'rank']}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank=10  #top 10 words;     \n",
    "res={}\n",
    "for c in data['question_type'].unique():\n",
    "    dic=dfdic(data.loc[data['question_type']==c, 'question_c'])\n",
    "    line=sorted(dic.values(), reverse=True)[rank:(rank+1)][0]   \n",
    "    keywrd=[k for k, v in dic.items() if v>line]\n",
    "    res[c]=keywrd    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen here, question types do share similarities. For example, words such as ['which', 'following', 'what', 'or'], appear most often for both multi-select and single-select types. Words ['how', 'or', 'find] show up as top 10 in both rate and single-select question types. This would cause confusion in prediction later, and looking at the samples, even human being sometimes cannot differentiate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature engineering to boost prediction performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom textblob import TextBlob\\ndef sent(text):  \\n    sent=TextBlob(text).sentiment  \\n    return (sent[0], sent[1])  \\n\\ndata['pol']=data['question'].apply(lambda x: sent(x)[0])\\ndata['sub']=data['question'].apply(lambda x: sent(x)[1])\\n\""
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.loc[:, ['question_c', 'question_type', 'question']]\n",
    "data['any_fol']=data['question_c'].str.contains('any') & data['question_c'].str.contains('following')  \n",
    "data['all_app']=data['question_c'].str.contains('all') & (data['question_c'].str.contains('apply') | data['question_c'].str.contains('select')) \n",
    "\n",
    "'''\n",
    "from textblob import TextBlob\n",
    "def sent(text):  \n",
    "    sent=TextBlob(text).sentiment  \n",
    "    return (sent[0], sent[1])  \n",
    "\n",
    "data['pol']=data['question'].apply(lambda x: sent(x)[0])\n",
    "data['sub']=data['question'].apply(lambda x: sent(x)[1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The sentiment such as polarity and subjectivity were also created (either based on original or cleaned question descriptions), but none turned out to improve model's prediction in a stable way. Code blocks thus commented out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classification modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data[['question_type', 'any_fol', 'all_app']]  \n",
    "X=data['question_c']\n",
    "\n",
    "rs=184  \n",
    "x_train, x_test, z_train, z_test = train_test_split(X, Y, test_size=0.25, random_state=rs)     \n",
    "ytrain=z_train['question_type']  \n",
    "ytest=z_test['question_type']\n",
    "\n",
    "tfidfv=TfidfVectorizer(min_df=1, ngram_range=(1, 2), stop_words=None, max_features=10000, \n",
    "                       strip_accents='unicode', norm='l2')    \n",
    "xtrain=tfidfv.fit_transform(x_train).todense()\n",
    "xtest=tfidfv.transform(x_test).todense()  \n",
    "\n",
    "col = ['feat_'+i for i in tfidfv.get_feature_names()]     \n",
    "xtrain = pd.DataFrame(xtrain, columns=col)    \n",
    "xtest = pd.DataFrame(xtest, columns=col) \n",
    "\n",
    "ztrain=pd.DataFrame(z_train.drop('question_type', axis=1)).reset_index(drop=True)\n",
    "ztest=pd.DataFrame(z_test.drop('question_type', axis=1)).reset_index(drop=True)\n",
    "\n",
    "xtrain=pd.concat([xtrain, ztrain], axis=1)\n",
    "xtest=pd.concat([xtest, ztest], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest predictions of test data\n",
      "\n",
      "Accuracy\n",
      "0.8504098360655737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rs=95\n",
    "model=RandomForestClassifier(random_state=rs, n_estimators=80)\n",
    "cname='RandomForest'  \n",
    "\n",
    "model.fit(xtrain, ytrain)\n",
    "pred=model.predict(xtest)\n",
    "predproba=pd.DataFrame(model.predict_proba(xtest))\n",
    "      \n",
    "print(cname + ' predictions of test data'+'\\n')  \n",
    "print('Accuracy')\n",
    "print(accuracy_score(ytest, pred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>description</th>\n",
       "      <th>matrix-likert</th>\n",
       "      <th>multi-select</th>\n",
       "      <th>number</th>\n",
       "      <th>rate</th>\n",
       "      <th>single-select</th>\n",
       "      <th>textarea</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ground</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix-likert</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-select</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single-select</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>144</td>\n",
       "      <td>12</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textarea</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      description  matrix-likert  multi-select  number  rate  \\\n",
       "Ground                                                                  \n",
       "description    62           0              0             0       0      \n",
       "matrix-likert  0            19             0             0       2      \n",
       "multi-select   0            0              14            0       0      \n",
       "number         0            0              0             4       0      \n",
       "rate           0            0              0             0       54     \n",
       "single-select  3            0              5             0       7      \n",
       "textarea       0            0              0             0       1      \n",
       "All            65           19             19            4       64     \n",
       "\n",
       "Predicted      single-select  textarea  All  \n",
       "Ground                                       \n",
       "description    4              0         66   \n",
       "matrix-likert  0              0         21   \n",
       "multi-select   8              8         30   \n",
       "number         0              0         4    \n",
       "rate           10             2         66   \n",
       "single-select  144            12        171  \n",
       "textarea       11             118       130  \n",
       "All            177            140       488  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix')\n",
    "pd.crosstab(ytest, pred, rownames=['Ground'], colnames=['Predicted'], margins=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>num_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix-likert</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-select</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rate</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single-select</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textarea</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision recall f1-score num_samples\n",
       "description    0.95      0.94   0.95     66        \n",
       "matrix-likert  1.00      0.90   0.95     21        \n",
       "multi-select   0.74      0.47   0.57     30        \n",
       "number         1.00      1.00   1.00     4         \n",
       "rate           0.84      0.82   0.83     66        \n",
       "single-select  0.81      0.84   0.83     171       \n",
       "textarea       0.84      0.91   0.87     130       "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Classification Report')    \n",
    "report={}    \n",
    "lines=classification_report(ytest, pred).split('\\n')    \n",
    "for l in lines[2:-5]: \n",
    "    report[l.split()[0]]=l.split()[1:]  \n",
    "reportdf=pd.DataFrame.from_dict(report, orient='index', columns=['precision', 'recall', 'f1-score', 'num_samples'])    \n",
    "reportdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check on misclassification samples:\n",
      "   Ground truth \"multi-select\" V.S. predicted \"single-select\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_c</th>\n",
       "      <th>question_type</th>\n",
       "      <th>pred</th>\n",
       "      <th>predprob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>which following expect receive website signing registration form</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>indicated organization wifi organization also outsource following</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>imagine service offered prescription refills delivery preferred method service</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>which following features product like willing pay more access</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.5500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>how research vehicle purchasing or leasing</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>what level education child or children</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>which products use</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>teach course any following areas</td>\n",
       "      <td>multi-select</td>\n",
       "      <td>single-select</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          question_c  \\\n",
       "199   which following expect receive website signing registration form                 \n",
       "537   indicated organization wifi organization also outsource following                \n",
       "635   imagine service offered prescription refills delivery preferred method service   \n",
       "1037  which following features product like willing pay more access                    \n",
       "1201  how research vehicle purchasing or leasing                                       \n",
       "1307  what level education child or children                                           \n",
       "1345  which products use                                                               \n",
       "1743  teach course any following areas                                                 \n",
       "\n",
       "     question_type           pred  predprob  \n",
       "199   multi-select  single-select  0.5125    \n",
       "537   multi-select  single-select  0.5125    \n",
       "635   multi-select  single-select  0.4750    \n",
       "1037  multi-select  single-select  0.5500    \n",
       "1201  multi-select  single-select  0.5625    \n",
       "1307  multi-select  single-select  0.6500    \n",
       "1345  multi-select  single-select  0.6625    \n",
       "1743  multi-select  single-select  0.4750    "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Check on misclassification samples:')   \n",
    "a=pd.DataFrame(x_test)\n",
    "b=pd.DataFrame(ytest)\n",
    "res_pred=pd.concat([a, b], axis=1)  \n",
    "res_pred['pred']=pred    \n",
    "res_pred['predprob']=[i.max() for i in model.predict_proba(xtest)]  \n",
    "print('   Ground truth \"multi-select\" V.S. predicted \"single-select\"')\n",
    "res_pred[(res_pred['question_type']=='multi-select') & (res_pred['pred']=='single-select')].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes and conclusions:   \n",
    "(1) The major stumbling block to the performance is in confusion between multi-select (ground trugh) and single-select/textareas (predict-to-be).           \n",
    "(2) Checking both the underlying data (final step) and words with top frequency, it seems that human being may also unable to make good judgements (on the mis-classified cases), simply based off the question descriptions. It may be helpful for survey makers to add sentence e.g. \"click all that apply\" to help survey audience.                                                                                                                                             (3) Different data samplings have been tested, the model displayed good accuracies quite stably.        \n",
    "(4) Also tested boosting models, it didn't outperform RandomForest to significant degree in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
